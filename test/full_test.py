import json
import os
import time
from fasttask_manager.manager import Manager
from requests import HTTPError
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from fasttask_manager.manager import Manager
from requests import HTTPError
from logging import getLogger

logger = getLogger(__name__)


auth_user = "admin"
auth_passwd = "passwd"

CONCURRENCY_LEVEL = 100  # åŒæ—¶è¿è¡Œçš„çº¿ç¨‹/ç”¨æˆ·æ•°é‡
REQUESTS_PER_THREAD = 100  # æ¯ä¸ªçº¿ç¨‹å‘é€çš„è¯·æ±‚æ•°é‡
TOTAL_REQUESTS = CONCURRENCY_LEVEL * REQUESTS_PER_THREAD  # æ€»è¯·æ±‚é‡ (1000)


auth_file = "samples/files/fasttask/conf/user_to_passwd.json"

manager_params = {
    "host": "127.0.0.1",
    "port": "9001",
    "protocol": "https",
    "task_name": "get_circle_area",
    "tries": 1,
    "logger": logger,
}
manager = Manager(**manager_params)
authed_manager = Manager(
    **manager_params,
    auth_user=auth_user,
    auth_passwd=auth_passwd,
)
logger.setLevel("WARNING")


data = {
    "r": 1,
}


def test_run(manager=manager):
    resp = manager.run(data)
    print(f"{resp=}")
    assert resp["result"]["area"] == 3.141592653589793
    print("test_run pass")


def test_create_check(manager=manager):
    result = manager.create_and_wait_result(data)
    print(f"{result=}")
    assert result["area"] == 3.141592653589793
    print("test_run pass")


def test_upload_download(manager=manager):
    with open("lp.bin", "wb") as f:
        for i in range(1024 * 120):
            f.write(b"0" * 1024)
    file_name = manager.upload("lp.bin")
    manager.download(file_name, "downloaded-lp.bin")
    assert (
        os.path.exists("downloaded-lp.bin")
        and os.path.getsize("downloaded-lp.bin") == 1024 * 120 * 1024
    )
    os.remove("lp.bin")
    os.remove("downloaded-lp.bin")
    print("test_upload_download pass")


def test_status_info(manager=manager):
    # manager.
    ...


def test_revoke(manager=manager):
    result_ids = []
    for _ in range(10):
        result_ids.append(manager.create_task(data)["id"])

    for result_id in result_ids:
        manager.revoke(result_id)
    time.sleep(5)
    for result_id in result_ids:
        state = manager.check(result_id)["state"]
        print(f"{result_id=} {state=}")
        assert state == "REVOKED", "task not revoked"


def test_all_api(manager, expect_access=True):
    for f in [
        test_run,
        test_create_check,
        test_upload_download,
        # test_status_info,
        test_revoke,
    ]:
        try:
            f(manager=manager)
            is_access = True
        except HTTPError as e:
            if e.response.status_code == 401:
                is_access = False
            else:
                raise e
        assert is_access == expect_access


def create_auth_file():
    with open(auth_file, "w") as f:
        json.dump(
            {
                auth_user: auth_passwd,
            },
            f,
            indent=2,
        )
    print(f"auth file created")


def test_auth():
    create_auth_file()
    print(f"auth file created,")
    wait(60)
    test_all_api(manager, expect_access=False)
    print("pass. prohibited unauthorized requests")

    test_all_api(authed_manager, expect_access=True)
    print("pass. allowed authed requests")

    os.remove(auth_file)
    print("auth file removed, wait for reload")
    wait(60)


def test_wrong_running_id_request(manager: Manager):
    resp = manager.check("wrong_id")
    assert resp["state"] == "FAILURE"
    assert "RUNNING_ID" in resp["result"]


def run_single_task_metadata(manager: Manager, request_id: int):
    """
    å•ä¸ªçº¿ç¨‹æ‰§è¡Œä»»åŠ¡çš„æ ¸å¿ƒé€»è¾‘ï¼šä»…åˆ›å»ºä»»åŠ¡å’Œæ£€æŸ¥çŠ¶æ€ã€‚
    """
    start_time = time.time()
    task_id = None

    try:
        task_id = manager.create_task(data)["id"]
        manager.check(task_id)["state"]
        manager.revoke(task_id)
        manager.check(task_id)["state"]
        return time.time() - start_time, True  # (è€—æ—¶, æˆåŠŸ)

    except Exception as e:
        # æ•è·ä»»ä½•å¼‚å¸¸ï¼ŒåŒ…æ‹¬ HTTPError
        print(f"\n[ERROR] Request {request_id} (Task ID: {task_id}) failed: {e}")
        return time.time() - start_time, False  # (è€—æ—¶, å¤±è´¥)


def test_concurrency_metadata_performance(unauthed_manager: Manager):
    """
    æµ‹è¯•æœåŠ¡åœ¨é«˜å¹¶å‘ä¸‹å¤„ç† create_task å’Œ check æ¥å£çš„æ€§èƒ½ã€‚
    """

    print("\n" + "=" * 50)
    print(f"ğŸš€ å¼€å§‹å…ƒæ•°æ®æ¥å£å¹¶å‘æµ‹è¯•ï¼šæ€»è¯·æ±‚é‡ {TOTAL_REQUESTS}")
    print(f"   å¹¶å‘æ•°: {CONCURRENCY_LEVEL}ï¼Œæ¯çº¿ç¨‹è¯·æ±‚: {REQUESTS_PER_THREAD}")
    print("=" * 50)

    start_global_time = time.time()
    all_futures = []

    # ä½¿ç”¨ ThreadPoolExecutor ç®¡ç†å¹¶å‘çº¿ç¨‹
    with ThreadPoolExecutor(max_workers=CONCURRENCY_LEVEL) as executor:
        request_counter = 0
        for _ in range(CONCURRENCY_LEVEL):
            for _ in range(REQUESTS_PER_THREAD):
                future = executor.submit(
                    run_single_task_metadata, unauthed_manager, request_counter
                )
                all_futures.append(future)
                request_counter += 1

    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶æ”¶é›†ç»“æœ
    total_time = 0
    success_count = 0

    for future in as_completed(all_futures):
        try:
            # future.result() ä¼šè¿”å› run_single_task_metadata çš„è¿”å›å€¼
            task_time, success = future.result(timeout=60)
            total_time += task_time
            if success:
                success_count += 1
        except Exception as e:
            print(f"[CRITICAL] Concurrency task failed unexpectedly: {e}")

    end_global_time = time.time()

    # --- æ€§èƒ½æŒ‡æ ‡è®¡ç®— ---
    elapsed_time = end_global_time - start_global_time
    average_response_time = total_time / TOTAL_REQUESTS if TOTAL_REQUESTS > 0 else 0
    throughput = TOTAL_REQUESTS / elapsed_time if elapsed_time > 0 else 0

    # --- æŠ¥å‘Šä¸æ–­è¨€ ---
    print("\n" + "-" * 50)
    print("ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ (create_task + check)")
    print("-" * 50)
    print(f"æ€»è¯·æ±‚æ•° (Total):      {TOTAL_REQUESTS} (æ¯æ¬¡åŒ…å« create+check)")
    print(f"æˆåŠŸè¯·æ±‚æ•° (Success):  {success_count}")
    print(f"æ€»è€—æ—¶ (Elapsed Time): {elapsed_time:.3f} ç§’")
    print(f"å¹³å‡å“åº”æ—¶é—´ (Avg RT): {average_response_time:.4f} ç§’/è¯·æ±‚ç»„")
    print(f"ååç‡ (RPS):          {throughput:.2f} è¯·æ±‚ç»„/ç§’")

    # æ ¸å¿ƒæ–­è¨€ï¼šæ‰€æœ‰è¯·æ±‚ç»„å¿…é¡»æˆåŠŸ
    assert success_count == TOTAL_REQUESTS, (
        f"å¹¶å‘æµ‹è¯•å¤±è´¥ï¼š{TOTAL_REQUESTS - success_count} ä¸ªè¯·æ±‚ç»„å¤±è´¥ã€‚"
    )
    assert throughput > 50, "ååç‡ä½äº 50 è¯·æ±‚ç»„/ç§’ã€‚"
    # æ ¹æ®éœ€è¦æ·»åŠ æ€§èƒ½é˜ˆå€¼æ–­è¨€
    # assert average_response_time < 0.1, "å¹³å‡å“åº”æ—¶é—´è¶…è¿‡é˜ˆå€¼ 0.1 ç§’ã€‚"

    print("-" * 50)
    print("test_concurrency_metadata_performance pass")


# todo
# test status info
# redis connection test
# release redis data


def wait(n, f=None):
    for i in range(n):
        if f and f():
            print("ready. continue...")
            return
        print(f"wait {i}/{n}...")
        time.sleep(1)


def is_ready(): ...


if __name__ == "__main__":
    for compose in [
        "samples/docker-compose-single_node.yml",
        "samples/docker-compose-distributed.yml",
        "samples/docker-compose-desktop-single_node.yml",
        "samples/docker-compose-desktop-distributed.yml",
    ]:
        print("-" * 20)
        print(f"testing {compose}...")
        print("-" * 20)
        print()

        os.system(f"docker compose -f '{compose}' up -d")
        wait(10)

        test_auth()
        test_all_api(manager)
        test_concurrency_metadata_performance(manager)

        os.system(f"docker compose -f '{compose}' down")

        print("-" * 20)
        print(f"all passed! {compose=}")
        print("-" * 20)
        print()
